{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Алгоритм шифра Цезаря\n",
    "def caesar_cipher(text, shift):\n",
    "    \"\"\"Шифрует текст с помощью шифра Цезаря\"\"\"\n",
    "    result = []\n",
    "    for char in text.lower():\n",
    "        if char in CHAR_TO_INDEX and char != 'none':\n",
    "            idx = CHAR_TO_INDEX[char]\n",
    "            new_idx = (idx - 1 + shift) % (len(INDEX_TO_CHAR) - 1)\n",
    "            result.append(INDEX_TO_CHAR[new_idx + 1])\n",
    "        else:\n",
    "            result.append(' ')\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Определяем словарь символов (только буквы + пробел)\n",
    "CHARS = set('abcdefghijklmnopqrstuvwxyz ')\n",
    "INDEX_TO_CHAR = ['none'] + list(CHARS)\n",
    "CHAR_TO_INDEX = {char: idx for idx, char in enumerate(INDEX_TO_CHAR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Генерация качественных тренировочных данных\n",
    "def generate_training_data(num_samples=5000, max_length=20):\n",
    "    \"\"\"Генерирует качественные тренировочные данные\"\"\"\n",
    "    phrases = []\n",
    "    \n",
    "    # Базовый словарь common words\n",
    "    words = [\n",
    "        'hello', 'world', 'ai', 'machine', 'learning', 'neural', 'network',\n",
    "        'python', 'code', 'data', 'science', 'computer', 'vision', 'deep',\n",
    "        'intelligence', 'algorithm', 'model', 'training', 'test', 'good',\n",
    "        'the', 'and', 'for', 'with', 'this', 'that', 'from', 'your', 'have',\n",
    "        'great', 'excellent', 'amazing', 'fantastic', 'wonderful', 'perfect'\n",
    "    ]\n",
    "    \n",
    "    # Простые шаблоны фраз\n",
    "    templates = [\n",
    "        \"{} {}\", \"{} {} {}\", \"{} {} {} {}\", \"the {} {}\", \"my {} {}\",\n",
    "        \"this is {}\", \"i love {}\", \"we need {}\", \"let's try {}\", \"{} and {}\"\n",
    "    ]\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Выбираем случайный шаблон\n",
    "        template = random.choice(templates)\n",
    "        \n",
    "        # Заполняем шаблон словами\n",
    "        phrase = template.format(*random.sample(words, template.count('{}')))\n",
    "        phrase = phrase[:max_length].lower().strip()\n",
    "        \n",
    "        # Убедимся, что фраза содержит только допустимые символы\n",
    "        clean_phrase = ''.join([c for c in phrase if c in CHARS or c == ' '])\n",
    "        if len(clean_phrase) >= 3:  # Минимальная длина\n",
    "            phrases.append(clean_phrase)\n",
    "    \n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Создаем датасет\n",
    "class CaesarDataset(Dataset):\n",
    "    def __init__(self, phrases, shift=3):\n",
    "        self.phrases = phrases\n",
    "        self.shift = shift\n",
    "        self.max_len = 30\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.phrases)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        original = self.phrases[idx].ljust(self.max_len, ' ')[:self.max_len]\n",
    "        encrypted = caesar_cipher(original, self.shift)\n",
    "        \n",
    "        # Кодируем в числовой формат\n",
    "        original_encoded = self.encode_text(original)\n",
    "        encrypted_encoded = self.encode_text(encrypted)\n",
    "        \n",
    "        return encrypted_encoded, original_encoded\n",
    "    \n",
    "    def encode_text(self, text):\n",
    "        encoded = torch.zeros(self.max_len, dtype=torch.long)\n",
    "        for i, char in enumerate(text[:self.max_len]):\n",
    "            encoded[i] = CHAR_TO_INDEX.get(char, 0)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Упрощенная и улучшенная модель\n",
    "class SimpleCaesarNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=16, hidden_dim=64):\n",
    "        super(SimpleCaesarNet, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True, num_layers=1)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.rnn(x)\n",
    "        return self.fc(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Функция для вычисления accuracy\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    \"\"\"Вычисляет accuracy посимвольно\"\"\"\n",
    "    _, predicted = torch.max(predictions, 2)\n",
    "    correct = (predicted == targets).float()\n",
    "    return correct.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация тренировочных данных...\n",
      "Сгенерировано 3000 фраз\n",
      "Примеры фраз: ['this is have', 'i love data', 'for world computer neural', 'my the machine', 'the fantastic machine']\n"
     ]
    }
   ],
   "source": [
    "# 7. Генерация данных\n",
    "print(\"Генерация тренировочных данных...\")\n",
    "phrases = generate_training_data(3000, 25)  # Меньше данных, но качественнее\n",
    "\n",
    "print(f\"Сгенерировано {len(phrases)} фраз\")\n",
    "print(\"Примеры фраз:\", phrases[:5])\n",
    "\n",
    "# Создаем датасет и DataLoader\n",
    "dataset = CaesarDataset(phrases, shift=3)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Инициализация модели\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCaesarNet(len(INDEX_TO_CHAR)).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем padding\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение...\n",
      "Epoch 1/5, Loss: 1.6704, Acc: 62.22%, Time: 4.32s\n",
      "Epoch 2/5, Loss: 0.3780, Acc: 94.63%, Time: 4.82s\n",
      "Epoch 3/5, Loss: 0.0914, Acc: 99.48%, Time: 3.87s\n",
      "Epoch 4/5, Loss: 0.0360, Acc: 99.91%, Time: 3.60s\n",
      "Epoch 5/5, Loss: 0.0182, Acc: 100.00%, Time: 3.99s\n"
     ]
    }
   ],
   "source": [
    "# 9. Обучение модели с мониторингом\n",
    "num_epochs = 5\n",
    "print(\"Начинаем обучение...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for encrypted, original in dataloader:\n",
    "        encrypted = encrypted.to(device)\n",
    "        original = original.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(encrypted)\n",
    "        \n",
    "        # Вычисляем loss только для non-padding символов\n",
    "        loss = criterion(outputs.view(-1, len(INDEX_TO_CHAR)), original.view(-1))\n",
    "        acc = calculate_accuracy(outputs, original)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_acc = total_acc / len(dataloader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Acc: {avg_acc:.2%}, Time: {time.time()-start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Улучшенная функция дешифровки\n",
    "def decrypt_caesar(text, model):\n",
    "    \"\"\"Дешифрует текст с помощью обученной модели\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Кодируем входной текст\n",
    "        encoded = torch.zeros(30, dtype=torch.long)\n",
    "        clean_text = ''.join([c for c in text.lower() if c in CHARS or c == ' '])\n",
    "        \n",
    "        for i, char in enumerate(clean_text[:30]):\n",
    "            encoded[i] = CHAR_TO_INDEX.get(char, 0)\n",
    "        \n",
    "        encoded = encoded.unsqueeze(0).to(device)\n",
    "        outputs = model(encoded)\n",
    "        \n",
    "        # Получаем наиболее вероятные символы\n",
    "        _, predicted = torch.max(outputs, 2)\n",
    "        decrypted_chars = []\n",
    "        \n",
    "        for idx in predicted[0].cpu().numpy():\n",
    "            if idx != 0:  # Пропускаем padding\n",
    "                decrypted_chars.append(INDEX_TO_CHAR[idx])\n",
    "        \n",
    "        result = ''.join(decrypted_chars).strip()\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ТЕСТИРОВАНИЕ МОДЕЛИ\n",
      "==================================================\n",
      "Тестируем на сдвиге 3:\n",
      "  Оригинал: hello world\n",
      "  Зашифровано: zqjjdmpdwjg\n",
      "  Расшифровано: mnggt ctygvfffffffffffffffffff\n",
      "  Правильно: False\n",
      "\n",
      "  Оригинал: machine learning\n",
      "  Зашифровано: tiezolqmjqiwlolr\n",
      "  Расшифровано: l gmmdn gn ydmdfffffffffffffff\n",
      "  Правильно: False\n",
      "\n",
      "  Оригинал: neural network\n",
      "  Зашифровано: lqxwijmlqvpdwa\n",
      "  Расшифровано: dnwn g dnactyudddfffffffffffff\n",
      "  Правильно: False\n",
      "\n",
      "  Оригинал: deep learning\n",
      "  Зашифровано: gqqkmjqiwlolr\n",
      "  Расшифровано: vnne gn ydmdffffffffffffffffff\n",
      "  Правильно: False\n",
      "\n",
      "  Оригинал: artificial intelligence\n",
      "  Зашифровано: iwvoyoeoijmolvqjjorqleq\n",
      "  Расшифровано: yamomgm g mdanggmfndgnddddfff\n",
      "  Правильно: False\n",
      "\n",
      "  Оригинал: test phrase\n",
      "  Зашифровано: vqbvmkzwibq\n",
      "  Расшифровано: aniamemy indddddffffffffffffff\n",
      "  Правильно: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 11. Тестирование на простых примерах\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ТЕСТИРОВАНИЕ МОДЕЛИ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Тестируем только на одном сдвиге (том, на котором обучали)\n",
    "test_phrases = [\n",
    "    \"hello world\",\n",
    "    \"machine learning\",\n",
    "    \"neural network\",\n",
    "    \"deep learning\",\n",
    "    \"artificial intelligence\",\n",
    "    \"test phrase\"\n",
    "]\n",
    "\n",
    "print(\"Тестируем на сдвиге 3:\")\n",
    "for phrase in test_phrases:\n",
    "    encrypted = caesar_cipher(phrase, 3)\n",
    "    decrypted = decrypt_caesar(encrypted, model)\n",
    "    \n",
    "    print(f\"  Оригинал: {phrase}\")\n",
    "    print(f\"  Зашифровано: {encrypted}\")\n",
    "    print(f\"  Расшифровано: {decrypted}\")\n",
    "    print(f\"  Правильно: {decrypted == phrase}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Дообучение для сдвига 1...\n",
      "  Сдвиг 1, Epoch 1, Loss: 1.4326\n",
      "  Сдвиг 1, Epoch 2, Loss: 0.2468\n",
      "  Сдвиг 1, Epoch 3, Loss: 0.1092\n",
      "  Сдвиг 1, Epoch 4, Loss: 0.0650\n",
      "  Сдвиг 1, Epoch 5, Loss: 0.0438\n",
      "\n",
      "Результаты для сдвига 1:\n",
      "  hello world -> hello worldggggggggggggggggggg (False)\n",
      "  machine learning -> machine learninggggggggggggggg (False)\n",
      "  neural network -> neural networkrggggggggggggggg (False)\n",
      "\n",
      "\n",
      "Дообучение для сдвига 3...\n",
      "  Сдвиг 3, Epoch 1, Loss: 0.3082\n",
      "  Сдвиг 3, Epoch 2, Loss: 0.0432\n",
      "  Сдвиг 3, Epoch 3, Loss: 0.0234\n",
      "  Сдвиг 3, Epoch 4, Loss: 0.0162\n",
      "  Сдвиг 3, Epoch 5, Loss: 0.0124\n",
      "\n",
      "Результаты для сдвига 3:\n",
      "  hello world -> hello worldngggggggggggggggggg (False)\n",
      "  machine learning -> machine learninggggggggggggggg (False)\n",
      "  neural network -> neural networkkggggggggggggggg (False)\n",
      "\n",
      "\n",
      "Дообучение для сдвига 5...\n",
      "  Сдвиг 5, Epoch 1, Loss: 1.7444\n",
      "  Сдвиг 5, Epoch 2, Loss: 0.3046\n",
      "  Сдвиг 5, Epoch 3, Loss: 0.1385\n",
      "  Сдвиг 5, Epoch 4, Loss: 0.0855\n",
      "  Сдвиг 5, Epoch 5, Loss: 0.0586\n",
      "\n",
      "Результаты для сдвига 5:\n",
      "  hello world -> hello worlddgggggggggggggggggg (False)\n",
      "  machine learning -> machine learninggggggggggggggg (False)\n",
      "  neural network -> neural network ggggggggggggggg (False)\n",
      "\n",
      "\n",
      "Дообучение для сдвига 7...\n",
      "  Сдвиг 7, Epoch 1, Loss: 1.1030\n",
      "  Сдвиг 7, Epoch 2, Loss: 0.1906\n",
      "  Сдвиг 7, Epoch 3, Loss: 0.0942\n",
      "  Сдвиг 7, Epoch 4, Loss: 0.0603\n",
      "  Сдвиг 7, Epoch 5, Loss: 0.0426\n",
      "\n",
      "Результаты для сдвига 7:\n",
      "  hello world -> hello worlddddddddffffffffffff (False)\n",
      "  machine learning -> machine learningggggffffffffff (False)\n",
      "  neural network -> neural networkffffffffffffffff (False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12. Проверка на разных сдвигах (после дообучения)\n",
    "def train_for_shift(shift, num_epochs=10):\n",
    "    \"\"\"Дообучаем модель для конкретного сдвига\"\"\"\n",
    "    print(f\"\\nДообучение для сдвига {shift}...\")\n",
    "    \n",
    "    dataset_shift = CaesarDataset(phrases, shift=shift)\n",
    "    dataloader_shift = DataLoader(dataset_shift, batch_size=32, shuffle=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for encrypted, original in dataloader_shift:\n",
    "            encrypted = encrypted.to(device)\n",
    "            original = original.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(encrypted)\n",
    "            loss = criterion(outputs.view(-1, len(INDEX_TO_CHAR)), original.view(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"  Сдвиг {shift}, Epoch {epoch+1}, Loss: {total_loss/len(dataloader_shift):.4f}\")\n",
    "\n",
    "# Тестируем разные сдвиги последовательно\n",
    "for test_shift in [1, 3, 5, 7]:\n",
    "    train_for_shift(test_shift, num_epochs=5)\n",
    "    \n",
    "    print(f\"\\nРезультаты для сдвига {test_shift}:\")\n",
    "    for phrase in test_phrases[:3]:  # Только первые 3 для brevity\n",
    "        encrypted = caesar_cipher(phrase, test_shift)\n",
    "        decrypted = decrypt_caesar(encrypted, model)\n",
    "        \n",
    "        print(f\"  {phrase} -> {decrypted} ({decrypted == phrase})\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
