{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pokhiliy_EY\\AppData\\Local\\Temp\\ipykernel_13516\\1828702903.py:2: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/simpsons_script_lines.csv')\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('data/simpsons_script_lines.csv')\n",
    "phrases = df['normalized_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 29\n",
      "Символы: ['<PAD>', 'g', 'u', 'f', 'x', '-', 'w', 'y', 'a', 'z', 'h', 'c', 'i', 'b', 'd', ' ', 'r', 's', 'j', 'm', 'l', 'q', 'p', 'o', 't', 'e', 'k', 'n', 'v']\n"
     ]
    }
   ],
   "source": [
    "# Создаем словарь символов\n",
    "CHARS = set('abcdefghijklmnopqrstuvwxyz -')\n",
    "INDEX_TO_CHAR = ['<PAD>'] + list(CHARS)\n",
    "CHAR_TO_INDEX = {char: idx for idx, char in enumerate(INDEX_TO_CHAR)}\n",
    "\n",
    "print(f\"Размер словаря: {len(INDEX_TO_CHAR)}\")\n",
    "print(f\"Символы: {INDEX_TO_CHAR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "MAX_LEN = 50\n",
    "text_data = []\n",
    "\n",
    "for phrase in phrases:\n",
    "    if type(phrase) is str:\n",
    "        # Оставляем только разрешенные символы\n",
    "        clean_phrase = ''.join([c for c in phrase.lower() if c in CHARS])\n",
    "        if len(clean_phrase) > 0:\n",
    "            text_data.append(clean_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность данных: torch.Size([132067, 50])\n"
     ]
    }
   ],
   "source": [
    "# Создаем тензор с данными\n",
    "X = torch.zeros((len(text_data), MAX_LEN), dtype=torch.long)\n",
    "\n",
    "for i, phrase in enumerate(text_data):\n",
    "    for j, char in enumerate(phrase[:MAX_LEN]):\n",
    "        X[i, j] = CHAR_TO_INDEX.get(char, 0)  # 0 = <PAD>\n",
    "    # Заполняем оставшиеся позиции паддингом\n",
    "    for j in range(len(phrase), MAX_LEN):\n",
    "        X[i, j] = 0\n",
    "\n",
    "print(f\"Размерность данных: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cpu\n"
     ]
    }
   ],
   "source": [
    "# Определяем устройство\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используемое устройство: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем RNN модель\n",
    "class SimpsonRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(SimpsonRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(1, batch_size, self.hidden_dim).to(device)\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, hidden = self.rnn(embedded, hidden)\n",
    "        output = self.fc(rnn_out.contiguous().view(-1, self.hidden_dim))\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель создана:\n",
      "- Размер словаря: 29\n",
      "- Размер эмбеддингов: 64\n",
      "- Размер скрытого состояния: 128\n"
     ]
    }
   ],
   "source": [
    "# Параметры модели\n",
    "VOCAB_SIZE = len(INDEX_TO_CHAR)\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = SimpsonRNN(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Игнорируем паддинг\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Модель создана:\")\n",
    "print(f\"- Размер словаря: {VOCAB_SIZE}\")\n",
    "print(f\"- Размер эмбеддингов: {EMBED_DIM}\")\n",
    "print(f\"- Размер скрытого состояния: {HIDDEN_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "def train_model(model, X, epochs=2, batch_size=100):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "        num_batches = len(X) // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            # Берем батч\n",
    "            batch = X[i*batch_size:(i+1)*batch_size].to(device)\n",
    "            \n",
    "            # Входные данные: все символы кроме последнего\n",
    "            X_batch = batch[:, :-1]\n",
    "            # Целевые данные: все символы кроме первого\n",
    "            Y_batch = batch[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Прямой проход\n",
    "            outputs, _ = model(X_batch)\n",
    "            loss = criterion(outputs, Y_batch)\n",
    "            \n",
    "            # Обратный проход\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Эпоха {epoch+1}/{epochs}, Время: {epoch_time:.2f}с, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Генерируем пример после каждой эпохи\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            generated = generate_text(model, \"homer\", length=50, temperature=0.8)\n",
    "            print(f\"Сгенерированный текст: '{generated}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для генерации текста\n",
    "def generate_text(model, start_text, length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Преобразуем начальный текст в индексы\n",
    "        chars = [c for c in start_text.lower() if c in CHAR_TO_INDEX]\n",
    "        if not chars:\n",
    "            chars = ['h']  # fallback\n",
    "            \n",
    "        input_indices = [CHAR_TO_INDEX[c] for c in chars]\n",
    "        input_tensor = torch.tensor([input_indices]).to(device)\n",
    "        \n",
    "        hidden = None\n",
    "        generated_text = chars.copy()\n",
    "        \n",
    "        for _ in range(length):\n",
    "            # Получаем предсказания\n",
    "            output, hidden = model(input_tensor, hidden)\n",
    "            \n",
    "            # Применяем температуру\n",
    "            output = output[-1] / temperature\n",
    "            probabilities = torch.softmax(output, dim=-1)\n",
    "            \n",
    "            # Выбираем следующий символ\n",
    "            next_char_idx = torch.multinomial(probabilities, 1).item()\n",
    "            \n",
    "            # Пропускаем паддинг\n",
    "            if next_char_idx == 0:\n",
    "                continue\n",
    "                \n",
    "            next_char = INDEX_TO_CHAR[next_char_idx]\n",
    "            generated_text.append(next_char)\n",
    "            \n",
    "            # Обновляем вход для следующей итерации\n",
    "            input_tensor = torch.tensor([[next_char_idx]]).to(device)\n",
    "        \n",
    "        return ''.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение...\n",
      "Эпоха 1/2, Время: 32.21с, Loss: 1.8050\n",
      "Эпоха 2/2, Время: 24.16с, Loss: 1.6165\n"
     ]
    }
   ],
   "source": [
    "# Обучаем модель\n",
    "print(\"Начинаем обучение...\")\n",
    "train_model(model, X, epochs=2, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ТЕСТИРОВАНИЕ ГЕНЕРАЦИИ\n",
      "==================================================\n",
      "Стартер: 'homer' -> Генерация: 'homer in the bart you know if i hav'\n",
      "Стартер: 'bart' -> Генерация: 'bart call him sister parmbally sun'\n",
      "Стартер: 'lisa' -> Генерация: 'lisa the file you a good the are y'\n",
      "Стартер: 'marge' -> Генерация: 'marge her isnt you have a brink you'\n"
     ]
    }
   ],
   "source": [
    "# Тестируем генерацию\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ТЕСТИРОВАНИЕ ГЕНЕРАЦИИ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_starters = [\"homer\", \"bart\", \"lisa\", \"marge\"]\n",
    "\n",
    "\n",
    "for starter in test_starters:\n",
    "    generated = generate_text(model, starter, length=30, temperature=0.7)\n",
    "    print(f\"Стартер: '{starter}' -> Генерация: '{generated}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
